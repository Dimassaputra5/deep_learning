{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebab76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jcopdl.callback import set_config, Callback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f192459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cb0043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 128\n",
    "crop_size = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(crop_size, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(235),\n",
    "    transforms.CenterCrop(crop_size),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.ImageFolder('data/data/train/', transform=train_transform)\n",
    "trainloader = DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
    "testset = datasets.ImageFolder('data/data/test/', transform=test_transform)\n",
    "testloader = DataLoader(testset, batch_size=bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a19ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2cat, idx_class = trainset.classes, trainset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d33ea65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 224, 224]), torch.Size([128]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature, target = next(iter(trainloader))\n",
    "feature.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fe484",
   "metadata": {},
   "source": [
    "# arsitektur dan config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d9f0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_feature, out_feature, padding=1, stride=1,\n",
    "                  activation=\"relu\", maxpool=True, kernel_size=3,\n",
    "                  kernel_size_pool=2, pool_stride=2)-> list[nn.Sequential]:\n",
    "    \"\"\"\n",
    "The conv_block function is designed to construct a sequential block of convolutional layers, complete with optional activation and max pooling. This is extremely useful for creating modular building blocks in Convolutional Neural Network (CNN) architectures, which we frequently utilize in notebooks and Kaggle.\n",
    "\n",
    "Parameters\n",
    "in_feature (int): The number of input channels (input features) for the convolutional layer.\n",
    "out_feature (int): The number of output channels (output features) to be produced by the convolutional layer.\n",
    "padding (int, optional, default=1): The amount of padding applied to the convolutional layer.\n",
    "stride (int, optional, default=1): The stride for the convolutional kernel's movement.\n",
    "activation (str, optional, default=\"relu\"): The type of activation function to use after the convolutional layer. Currently supports \"relu\".\n",
    "maxpool (bool, optional, default=True): If True, a max pooling layer will be appended after the activation.\n",
    "kernel_size (int, optional, default=3): The kernel (filter) size for the convolutional layer.\n",
    "kernel_size_pool (int, optional, default=2): The kernel size for the max pooling layer, if maxpool is enabled.\n",
    "pool_stride (int, optional, default=2): The stride for the max pooling layer, if maxpool is enabled.\n",
    "Returns\n",
    "nn.Sequential: Returns a PyTorch nn.Sequential object containing the following sequence of layers:\n",
    "A Convolutional layer (nn.Conv2d)\n",
    "An Activation function (e.g., nn.ReLU), if specified\n",
    "A Max Pooling layer (nn.MaxPool2d), if maxpool is True\n",
    "    \"\"\"\n",
    "    layers = [nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, padding=padding, stride=stride)]\n",
    "    if activation == \"relu\":\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == \"leakyrelu\":\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == \"sigmoid\":\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == \"tanh\":\n",
    "        layers.append(nn.Tanh())\n",
    "    if maxpool:\n",
    "        layers.append(nn.MaxPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "    else:\n",
    "        layers.append(nn.AvgPool2d(kernel_size=kernel_size_pool, stride=pool_stride))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def linear_block(in_features, out_features, activation='relu', dropout=0.0):\n",
    "    layers = [nn.Linear(in_features, out_features)]\n",
    "    # if batch_norm:\n",
    "    #     layers.append(BatchNorm1d(out_features))\n",
    "    if activation == 'relu':\n",
    "        layers.append(nn.ReLU())\n",
    "    elif activation == 'sigmoid':\n",
    "        layers.append(nn.Sigmoid())\n",
    "    elif activation == 'tanh':\n",
    "        layers.append(nn.Tanh())\n",
    "    elif activation == 'leakyrelu':\n",
    "        layers.append(nn.LeakyReLU())\n",
    "    elif activation == 'softmax':\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "    elif activation == 'elu':\n",
    "        layers.append(nn.ELU())\n",
    "    elif activation == 'selu':\n",
    "        layers.append(nn.SELU())\n",
    "    elif activation == 'lsoftmax':\n",
    "        layers.append(nn.LogSoftmax(dim=1))\n",
    "    if dropout > 0.0:\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d845d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv_block(3, 8),\n",
    "            conv_block(8, 16),\n",
    "            conv_block(16, 32),\n",
    "            conv_block(32, 64),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            linear_block(64 * 14 * 14, 512, activation='relu', dropout=dropout),\n",
    "            linear_block(512, 256, activation='relu', dropout=dropout),\n",
    "            linear_block(256, len(label2cat), activation='lsoftmax')\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e88f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = set_config({\n",
    "    \"batch_size\": bs,\n",
    "    \"crop_size\": crop_size\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b8e18",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb1783c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "critetion = nn.NLLLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "callback = Callback(model, config, outdir='models' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627216c9",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1540e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_fn(mode, dataset, dataloader, model, criterion, optimizer, device):\n",
    "    from tqdm.auto import tqdm\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "    elif mode == 'test':\n",
    "        model.eval()\n",
    "    cost = correct = 0\n",
    "    for feature, target in tqdm(dataloader, desc=mode.title()):\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        output = model(feature)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if mode == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        cost += loss.item() * feature.shape[0]\n",
    "        correct += (output.argmax(dim=1) == target).sum().item()\n",
    "    cost = cost / len(dataset)\n",
    "    accuracy = correct / len(dataset)\n",
    "    return cost, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    train_cost, train_acc = loop_fn('train', trainset, trainloader, model, criterion, optimizer, device)\n",
    "    with torch.no_grad():\n",
    "        test_cost, test_acc = loop_fn('test', testset, testloader, model, criterion, optimizer, device)\n",
    "\n",
    "    callback.log(train_cost=train_cost, test_cost=test_cost, test_score=test_acc, train_score=train_acc)\n",
    "    callback.save_checkpoint()\n",
    "    callback.cost_runtime_plotting()\n",
    "    callback.score_runtime_plotting()\n",
    "    if callback.early_stopping(model, monitor='test_score', load_best_when_stop=True):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        callback.plot_cost()\n",
    "        callback.plot_score()\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Train Cost: {train_cost:.4f}, Test Cost: {test_cost:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcopdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
